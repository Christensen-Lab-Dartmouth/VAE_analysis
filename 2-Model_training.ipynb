{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "from keras.layers import Input, Dense, Lambda, Layer, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics, optimizers\n",
    "from keras.callbacks import Callback\n",
    "import keras\n",
    "\n",
    "import pydot\n",
    "#import graphviz\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.2.1'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(keras.__version__)\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get a GPU session and reserve memory\n",
    "def get_session(gpu_fraction=0.3):\n",
    "    '''Assume that you have 6GB of GPU memory and want to allocate ~2GB'''\n",
    "\n",
    "    num_threads = os.environ.get('OMP_NUM_THREADS')\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n",
    "\n",
    "    if num_threads:\n",
    "        return tf.Session(config=tf.ConfigProto(\n",
    "            gpu_options=gpu_options, intra_op_parallelism_threads=num_threads))\n",
    "    else:\n",
    "        return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "KTF.set_session(get_session(.90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for reparameterization trick to make model differentiable\n",
    "def sampling(args):\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    # Function with args required for Keras Lambda function\n",
    "    z_mean, z_log_var = args\n",
    "\n",
    "    # Draw epsilon of the same shape from a standard normal distribution\n",
    "    epsilon = K.random_normal(shape=tf.shape(z_mean), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    \n",
    "    # The latent vector is non-deterministic and differentiable\n",
    "    # in respect to z_mean and z_log_var\n",
    "    z = z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "    return z\n",
    "\n",
    "\n",
    "class CustomVariationalLayer(Layer):\n",
    "    \"\"\"\n",
    "    Define a custom layer that learns and performs the training\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        # https://keras.io/layers/writing-your-own-keras-layers/\n",
    "        self.is_placeholder = True\n",
    "        super(CustomVariationalLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def vae_loss(self, x_input, x_decoded):\n",
    "        reconstruction_loss = original_dim * metrics.binary_crossentropy(x_input, x_decoded)\n",
    "        kl_loss = - 0.5 * K.sum(1 + z_log_var_encoded - K.square(z_mean_encoded) - \n",
    "                                K.exp(z_log_var_encoded), axis=-1)\n",
    "        return K.mean(reconstruction_loss + (K.get_value(beta) * kl_loss))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        x_decoded = inputs[1]\n",
    "        loss = self.vae_loss(x, x_decoded)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        # We won't actually use the output.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WarmUpCallback(Callback):\n",
    "    def __init__(self, beta, kappa):\n",
    "        self.beta = beta\n",
    "        self.kappa = kappa\n",
    "    # Behavior on each epoch\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if K.get_value(self.beta) <= 1:\n",
    "            K.set_value(self.beta, K.get_value(self.beta) + self.kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('seaborn-notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vars and HPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set hyper parameters\n",
    "original_dim = 300000\n",
    "latent_dim = 100\n",
    "\n",
    "batch_size = 50\n",
    "epochs = 50\n",
    "learning_rate = 0.0005\n",
    "\n",
    "epsilon_std = 1.0\n",
    "beta = K.variable(0)\n",
    "kappa = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load methylation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-f1646dc13a3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmethyl_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TCGA_BRCA_top300kMAD_cpg.tsv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmethyl_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethyl_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethyl_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmethyl_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1003\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skipfooter not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1005\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'as_recarray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1746\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1747\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1748\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1749\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1750\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read (pandas\\_libs\\parsers.c:10862)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory (pandas\\_libs\\parsers.c:11138)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows (pandas\\_libs\\parsers.c:12175)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data (pandas\\_libs\\parsers.c:14136)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens (pandas\\_libs\\parsers.c:14858)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype (pandas\\_libs\\parsers.c:15629)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mis_integer_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m    738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m     \"\"\"\n\u001b[0;32m    742\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "methyl_file = os.path.join('data', 'TCGA_BRCA_top300kMAD_cpg.tsv')\n",
    "methyl_df = pd.read_table(methyl_file, index_col=0)\n",
    "print(methyl_df.shape)\n",
    "methyl_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(862, 300000)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cg00122254</th>\n",
       "      <th>cg07950803</th>\n",
       "      <th>cg06020352</th>\n",
       "      <th>cg00014104</th>\n",
       "      <th>cg04108240</th>\n",
       "      <th>cg19537719</th>\n",
       "      <th>cg11461670</th>\n",
       "      <th>cg26282887</th>\n",
       "      <th>cg18552413</th>\n",
       "      <th>cg05595753</th>\n",
       "      <th>...</th>\n",
       "      <th>cg22089024</th>\n",
       "      <th>cg23289779</th>\n",
       "      <th>cg01870834</th>\n",
       "      <th>cg00901843</th>\n",
       "      <th>cg25934198</th>\n",
       "      <th>cg13688262</th>\n",
       "      <th>cg14428878</th>\n",
       "      <th>cg18131582</th>\n",
       "      <th>cg12917938</th>\n",
       "      <th>cg06904956</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7796806090_R04C01</th>\n",
       "      <td>0.046660</td>\n",
       "      <td>0.897248</td>\n",
       "      <td>0.652521</td>\n",
       "      <td>0.471406</td>\n",
       "      <td>0.775688</td>\n",
       "      <td>0.495734</td>\n",
       "      <td>0.438540</td>\n",
       "      <td>0.510294</td>\n",
       "      <td>0.561539</td>\n",
       "      <td>0.768544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060164</td>\n",
       "      <td>0.723294</td>\n",
       "      <td>0.398821</td>\n",
       "      <td>0.503005</td>\n",
       "      <td>0.702736</td>\n",
       "      <td>0.774951</td>\n",
       "      <td>0.841170</td>\n",
       "      <td>0.559773</td>\n",
       "      <td>0.806210</td>\n",
       "      <td>0.840528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6285633051_R04C01</th>\n",
       "      <td>0.058873</td>\n",
       "      <td>0.486256</td>\n",
       "      <td>0.352591</td>\n",
       "      <td>0.427361</td>\n",
       "      <td>0.913327</td>\n",
       "      <td>0.720762</td>\n",
       "      <td>0.484323</td>\n",
       "      <td>0.535114</td>\n",
       "      <td>0.266286</td>\n",
       "      <td>0.819594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061524</td>\n",
       "      <td>0.670289</td>\n",
       "      <td>0.478324</td>\n",
       "      <td>0.467078</td>\n",
       "      <td>0.809887</td>\n",
       "      <td>0.867867</td>\n",
       "      <td>0.642287</td>\n",
       "      <td>0.583485</td>\n",
       "      <td>0.865380</td>\n",
       "      <td>0.864694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993943017_R04C02</th>\n",
       "      <td>0.079432</td>\n",
       "      <td>0.445756</td>\n",
       "      <td>0.789767</td>\n",
       "      <td>0.570244</td>\n",
       "      <td>0.837710</td>\n",
       "      <td>0.218656</td>\n",
       "      <td>0.302884</td>\n",
       "      <td>0.661226</td>\n",
       "      <td>0.326385</td>\n",
       "      <td>0.817745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044401</td>\n",
       "      <td>0.408273</td>\n",
       "      <td>0.727590</td>\n",
       "      <td>0.559788</td>\n",
       "      <td>0.910760</td>\n",
       "      <td>0.746987</td>\n",
       "      <td>0.413313</td>\n",
       "      <td>0.767292</td>\n",
       "      <td>0.848849</td>\n",
       "      <td>0.871472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7796806090_R03C01</th>\n",
       "      <td>0.056591</td>\n",
       "      <td>0.854925</td>\n",
       "      <td>0.496990</td>\n",
       "      <td>0.185658</td>\n",
       "      <td>0.882997</td>\n",
       "      <td>0.061131</td>\n",
       "      <td>0.026978</td>\n",
       "      <td>0.659007</td>\n",
       "      <td>0.429860</td>\n",
       "      <td>0.613741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024281</td>\n",
       "      <td>0.458832</td>\n",
       "      <td>0.648874</td>\n",
       "      <td>0.380753</td>\n",
       "      <td>0.772982</td>\n",
       "      <td>0.680736</td>\n",
       "      <td>0.818467</td>\n",
       "      <td>0.505687</td>\n",
       "      <td>0.859446</td>\n",
       "      <td>0.842765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999997079_R01C02</th>\n",
       "      <td>0.053748</td>\n",
       "      <td>0.178044</td>\n",
       "      <td>0.853712</td>\n",
       "      <td>0.174643</td>\n",
       "      <td>0.885674</td>\n",
       "      <td>0.067699</td>\n",
       "      <td>0.559529</td>\n",
       "      <td>0.728681</td>\n",
       "      <td>0.143848</td>\n",
       "      <td>0.749181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036990</td>\n",
       "      <td>0.318999</td>\n",
       "      <td>0.757237</td>\n",
       "      <td>0.473694</td>\n",
       "      <td>0.719295</td>\n",
       "      <td>0.830167</td>\n",
       "      <td>0.351490</td>\n",
       "      <td>0.192757</td>\n",
       "      <td>0.834724</td>\n",
       "      <td>0.857373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 300000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   cg00122254  cg07950803  cg06020352  cg00014104  cg04108240  \\\n",
       "7796806090_R04C01    0.046660    0.897248    0.652521    0.471406    0.775688   \n",
       "6285633051_R04C01    0.058873    0.486256    0.352591    0.427361    0.913327   \n",
       "9993943017_R04C02    0.079432    0.445756    0.789767    0.570244    0.837710   \n",
       "7796806090_R03C01    0.056591    0.854925    0.496990    0.185658    0.882997   \n",
       "3999997079_R01C02    0.053748    0.178044    0.853712    0.174643    0.885674   \n",
       "\n",
       "                   cg19537719  cg11461670  cg26282887  cg18552413  cg05595753  \\\n",
       "7796806090_R04C01    0.495734    0.438540    0.510294    0.561539    0.768544   \n",
       "6285633051_R04C01    0.720762    0.484323    0.535114    0.266286    0.819594   \n",
       "9993943017_R04C02    0.218656    0.302884    0.661226    0.326385    0.817745   \n",
       "7796806090_R03C01    0.061131    0.026978    0.659007    0.429860    0.613741   \n",
       "3999997079_R01C02    0.067699    0.559529    0.728681    0.143848    0.749181   \n",
       "\n",
       "                      ...      cg22089024  cg23289779  cg01870834  cg00901843  \\\n",
       "7796806090_R04C01     ...        0.060164    0.723294    0.398821    0.503005   \n",
       "6285633051_R04C01     ...        0.061524    0.670289    0.478324    0.467078   \n",
       "9993943017_R04C02     ...        0.044401    0.408273    0.727590    0.559788   \n",
       "7796806090_R03C01     ...        0.024281    0.458832    0.648874    0.380753   \n",
       "3999997079_R01C02     ...        0.036990    0.318999    0.757237    0.473694   \n",
       "\n",
       "                   cg25934198  cg13688262  cg14428878  cg18131582  cg12917938  \\\n",
       "7796806090_R04C01    0.702736    0.774951    0.841170    0.559773    0.806210   \n",
       "6285633051_R04C01    0.809887    0.867867    0.642287    0.583485    0.865380   \n",
       "9993943017_R04C02    0.910760    0.746987    0.413313    0.767292    0.848849   \n",
       "7796806090_R03C01    0.772982    0.680736    0.818467    0.505687    0.859446   \n",
       "3999997079_R01C02    0.719295    0.830167    0.351490    0.192757    0.834724   \n",
       "\n",
       "                   cg06904956  \n",
       "7796806090_R04C01    0.840528  \n",
       "6285633051_R04C01    0.864694  \n",
       "9993943017_R04C02    0.871472  \n",
       "7796806090_R03C01    0.842765  \n",
       "3999997079_R01C02    0.857373  \n",
       "\n",
       "[5 rows x 300000 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce the data size for model testing\n",
    "methyl_df2 = methyl_df.sample(original_dim, axis=1) # this is not correct when real training happens\n",
    "print(methyl_df2.shape)\n",
    "methyl_df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 10% test set randomly\n",
    "test_set_percent = 0.1\n",
    "methyl_test_df = methyl_df2.sample(frac=test_set_percent)\n",
    "methyl_train_df = methyl_df2.drop(methyl_test_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input place holder for methylation data with specific input size\n",
    "methyl_input = Input(shape=(original_dim, ))\n",
    "\n",
    "# Input layer is compressed into a mean and log variance vector of size `latent_dim`\n",
    "# Each layer is initialized with glorot uniform weights and each step (dense connections, batch norm,\n",
    "# and relu activation) are funneled separately\n",
    "# Each vector of length `latent_dim` are connected to the methyl input tensor\n",
    "z_mean_dense_linear = Dense(latent_dim, kernel_initializer='glorot_uniform')(methyl_input)\n",
    "z_mean_dense_batchnorm = BatchNormalization()(z_mean_dense_linear)\n",
    "z_mean_encoded = Activation('relu')(z_mean_dense_batchnorm)\n",
    "\n",
    "z_log_var_dense_linear = Dense(latent_dim, kernel_initializer='glorot_uniform')(methyl_input)\n",
    "z_log_var_dense_batchnorm = BatchNormalization()(z_log_var_dense_linear)\n",
    "z_log_var_encoded = Activation('relu')(z_log_var_dense_batchnorm)\n",
    "\n",
    "# return the encoded and randomly sampled z vector\n",
    "# Takes two keras layers as input to the custom sampling function layer with a `latent_dim` output\n",
    "z = Lambda(sampling, output_shape=(latent_dim, ))([z_mean_encoded, z_log_var_encoded])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The decoding layer is much simpler with a single layer glorot uniform initialized and sigmoid activation\n",
    "decoder_to_reconstruct = Dense(original_dim, kernel_initializer='glorot_uniform', activation='sigmoid')\n",
    "methyl_reconstruct = decoder_to_reconstruct(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder + Decoder = VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 300000)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 100)          30000100    input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 100)          30000100    input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 100)          400         dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 100)          400         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 100)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 100)          0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 100)          0           activation_5[0][0]               \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 300000)       30300000    lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "custom_variational_layer_3 (Cus [(None, 300000), (No 0           input_3[0][0]                    \n",
      "                                                                 dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 90,301,000\n",
      "Trainable params: 90,300,600\n",
      "Non-trainable params: 400\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atitus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Output \"custom_variational_layer_3\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"custom_variational_layer_3\" during training.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "adam = optimizers.Adam(lr=learning_rate)\n",
    "vae_layer = CustomVariationalLayer()([methyl_input, methyl_reconstruct])\n",
    "vae = Model(methyl_input, vae_layer)\n",
    "vae.compile(optimizer=adam, loss=None, loss_weights=[beta])\n",
    "\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1860\u001b[0m                 \u001b[0mshell\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1861\u001b[1;33m                 stderr=subprocess.PIPE, stdout=subprocess.PIPE)\n\u001b[0m\u001b[0;32m   1862\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[0;32m    708\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    710\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m    996\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 997\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m    998\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1866\u001b[0m                     prog=prog)\n\u001b[1;32m-> 1867\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] \"dot.exe\" not found in path.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-0c6327167b97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Visualize the connections of the custom VAE model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0moutput_model_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'figures'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'onehidden_vae_architecture.eps'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_model_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mSVG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dot'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'svg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[1;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \"\"\"\n\u001b[1;32m--> 135\u001b[1;33m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mdot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rankdir'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m# pydot raises a generic Exception here,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m# so no specific class can be caught.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[0;32m     32\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "# Visualize the connections of the custom VAE model\n",
    "output_model_file = os.path.join('figures', 'onehidden_vae_architecture.eps')\n",
    "plot_model(vae, to_file=output_model_file)\n",
    "\n",
    "SVG(model_to_dot(vae).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Error when checking model target: expected no data, but got:', array([[ 0.03308689,  0.82624223,  0.54685273, ...,  0.78407808,\n         0.87457004,  0.81861516],\n       [ 0.02959353,  0.43862998,  0.41818635, ...,  0.54273541,\n         0.83594015,  0.84685494],\n       [ 0.06567254,  0.67192673,  0.28095218, ...,  0.59994095,\n         0.88507839,  0.81780314],\n       ..., \n       [ 0.06619068,  0.64890409,  0.67049138, ...,  0.69258406,\n         0.87349869,  0.8943042 ],\n       [ 0.07569845,  0.29401364,  0.28774711, ...,  0.76286033,\n         0.90091877,  0.91070668],\n       [ 0.04509313,  0.8756331 ,  0.44706674, ...,  0.59246953,\n         0.83751562,  0.83921123]]))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1655\u001b[0m                 \u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1656\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1657\u001b[1;33m                 batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1658\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1659\u001b[0m                 \u001b[0mval_ins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_x\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mval_y\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mval_sample_weights\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m   1485\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1486\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1487\u001b[1;33m                                     exception_prefix='target')\n\u001b[0m\u001b[0;32m   1488\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[0;32m   1489\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m     54\u001b[0m             raise ValueError('Error when checking model ' +\n\u001b[0;32m     55\u001b[0m                              \u001b[0mexception_prefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m                              'expected no data, but got:', data)\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: ('Error when checking model target: expected no data, but got:', array([[ 0.03308689,  0.82624223,  0.54685273, ...,  0.78407808,\n         0.87457004,  0.81861516],\n       [ 0.02959353,  0.43862998,  0.41818635, ...,  0.54273541,\n         0.83594015,  0.84685494],\n       [ 0.06567254,  0.67192673,  0.28095218, ...,  0.59994095,\n         0.88507839,  0.81780314],\n       ..., \n       [ 0.06619068,  0.64890409,  0.67049138, ...,  0.69258406,\n         0.87349869,  0.8943042 ],\n       [ 0.07569845,  0.29401364,  0.28774711, ...,  0.76286033,\n         0.90091877,  0.91070668],\n       [ 0.04509313,  0.8756331 ,  0.44706674, ...,  0.59246953,\n         0.83751562,  0.83921123]]))"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hist = vae.fit(np.array(methyl_train_df),\n",
    "               shuffle=True,\n",
    "               epochs=epochs,\n",
    "               batch_size=batch_size,\n",
    "               validation_data=(np.array(methyl_test_df), np.array(methyl_test_df)),\n",
    "               callbacks=[WarmUpCallback(beta, kappa)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-82ab251b58c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Visualize training performance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mhist_plot_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'figures'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'onehidden_vae_training_300K-100.pdf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#hist_plot_file = os.path.join('figures', 'onehidden_vae_training_30K-1000.pdf')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#hist_plot_file = os.path.join('figures', 'onehidden_vae_training_100K-10.pdf')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualize training performance\n",
    "history_df = pd.DataFrame(hist.history)\n",
    "hist_plot_file = os.path.join('figures', 'onehidden_vae_training_300K-100.pdf') \n",
    "#hist_plot_file = os.path.join('figures', 'onehidden_vae_training_30K-1000.pdf') \n",
    "#hist_plot_file = os.path.join('figures', 'onehidden_vae_training_100K-10.pdf')\n",
    "#hist_plot_file = os.path.join('figures', 'onehidden_vae_training_100K-100.pdf')\n",
    "#hist_plot_file = os.path.join('figures', 'onehidden_vae_training_10K-100.pdf')\n",
    "ax = history_df.plot()\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('VAE Loss')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(hist_plot_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and output models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model to compress input\n",
    "encoder = Model(methyl_input, z_mean_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode methyl into the hidden/latent representation - and save output\n",
    "encoded_methyl_df = encoder.predict_on_batch(methyl_df2)\n",
    "encoded_methyl_df = pd.DataFrame(encoded_methyl_df, index=methyl_df2.index)\n",
    "\n",
    "encoded_methyl_df.columns.name = 'sample_id'\n",
    "encoded_methyl_df.columns = encoded_methyl_df.columns + 1\n",
    "#encoded_file = os.path.join('data', 'encoded_methyl_onehidden_warmup_batchnorm_100K-10.tsv')\n",
    "#encoded_file = os.path.join('data', 'encoded_methyl_onehidden_warmup_batchnorm_100K-100.tsv')\n",
    "#encoded_file = os.path.join('data', 'encoded_methyl_onehidden_warmup_batchnorm_10K-100.tsv')\n",
    "#encoded_file = os.path.join('data', 'encoded_methyl_onehidden_warmup_batchnorm_300K-1000.tsv')\n",
    "encoded_file = os.path.join('data', 'encoded_methyl_onehidden_warmup_batchnorm_300K-100.tsv')\n",
    "encoded_methyl_df.to_csv(encoded_file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_id\n",
      "72    2689.523682\n",
      "19    2261.734619\n",
      "3     2233.960938\n",
      "52    2158.137939\n",
      "76    1944.653687\n",
      "66    1915.777466\n",
      "78    1817.843872\n",
      "55    1793.530273\n",
      "39    1703.847656\n",
      "64    1642.765991\n",
      "dtype: float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sample_id\n",
       "88    98.864792\n",
       "43    89.600433\n",
       "40    73.793655\n",
       "25    70.327644\n",
       "93    68.710793\n",
       "97    66.469162\n",
       "51    40.531780\n",
       "89    37.308762\n",
       "45    21.683561\n",
       "42    19.556742\n",
       "dtype: float32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the most and least activated nodes\n",
    "top_active_nodes = encoded_methyl_df.sum(axis=0).sort_values(ascending=False)\n",
    "print(top_active_nodes.head(10))\n",
    "top_active_nodes.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f2bc46cd1d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg4AAAIDCAYAAABsJZbnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2b847db358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example distribution of latent layer\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(encoded_methyl_df.iloc[:, 50], encoded_methyl_df.iloc[:, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build a generator that can sample from the learned distribution\n",
    "decoder_input = Input(shape=(latent_dim, ))  # can generate from any sampled z vector\n",
    "_x_decoded_mean = decoder_to_reconstruct(decoder_input)\n",
    "decoder = Model(decoder_input, _x_decoded_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cg05609218</th>\n",
       "      <th>cg22931085</th>\n",
       "      <th>cg17251874</th>\n",
       "      <th>cg15207619</th>\n",
       "      <th>cg18069268</th>\n",
       "      <th>cg11787508</th>\n",
       "      <th>cg13337949</th>\n",
       "      <th>cg04485516</th>\n",
       "      <th>cg01828530</th>\n",
       "      <th>cg09648722</th>\n",
       "      <th>...</th>\n",
       "      <th>ch.9.1173620F</th>\n",
       "      <th>cg04300684</th>\n",
       "      <th>cg16770054</th>\n",
       "      <th>cg18900959</th>\n",
       "      <th>cg14847845</th>\n",
       "      <th>cg23107916</th>\n",
       "      <th>cg16751754</th>\n",
       "      <th>cg15457745</th>\n",
       "      <th>cg00849943</th>\n",
       "      <th>cg17289222</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7796806090_R04C01</th>\n",
       "      <td>0.672033</td>\n",
       "      <td>0.876269</td>\n",
       "      <td>0.767542</td>\n",
       "      <td>0.123064</td>\n",
       "      <td>0.973082</td>\n",
       "      <td>0.764291</td>\n",
       "      <td>0.045026</td>\n",
       "      <td>0.967063</td>\n",
       "      <td>0.780857</td>\n",
       "      <td>0.039814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037846</td>\n",
       "      <td>0.606236</td>\n",
       "      <td>0.931593</td>\n",
       "      <td>0.926697</td>\n",
       "      <td>0.860495</td>\n",
       "      <td>0.698333</td>\n",
       "      <td>0.932990</td>\n",
       "      <td>0.022119</td>\n",
       "      <td>0.015452</td>\n",
       "      <td>0.980561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6285633051_R04C01</th>\n",
       "      <td>0.729906</td>\n",
       "      <td>0.843547</td>\n",
       "      <td>0.671565</td>\n",
       "      <td>0.059589</td>\n",
       "      <td>0.977977</td>\n",
       "      <td>0.790845</td>\n",
       "      <td>0.022084</td>\n",
       "      <td>0.983528</td>\n",
       "      <td>0.836831</td>\n",
       "      <td>0.024214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022224</td>\n",
       "      <td>0.636163</td>\n",
       "      <td>0.962394</td>\n",
       "      <td>0.942780</td>\n",
       "      <td>0.848625</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.961438</td>\n",
       "      <td>0.012269</td>\n",
       "      <td>0.008690</td>\n",
       "      <td>0.993206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993943017_R04C02</th>\n",
       "      <td>0.693098</td>\n",
       "      <td>0.843114</td>\n",
       "      <td>0.466781</td>\n",
       "      <td>0.036274</td>\n",
       "      <td>0.960945</td>\n",
       "      <td>0.771037</td>\n",
       "      <td>0.029470</td>\n",
       "      <td>0.975914</td>\n",
       "      <td>0.902240</td>\n",
       "      <td>0.032599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041737</td>\n",
       "      <td>0.697151</td>\n",
       "      <td>0.967159</td>\n",
       "      <td>0.921050</td>\n",
       "      <td>0.807059</td>\n",
       "      <td>0.539523</td>\n",
       "      <td>0.965884</td>\n",
       "      <td>0.018012</td>\n",
       "      <td>0.019237</td>\n",
       "      <td>0.994381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 300000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   cg05609218  cg22931085  cg17251874  cg15207619  cg18069268  \\\n",
       "7796806090_R04C01    0.672033    0.876269    0.767542    0.123064    0.973082   \n",
       "6285633051_R04C01    0.729906    0.843547    0.671565    0.059589    0.977977   \n",
       "9993943017_R04C02    0.693098    0.843114    0.466781    0.036274    0.960945   \n",
       "\n",
       "                   cg11787508  cg13337949  cg04485516  cg01828530  cg09648722  \\\n",
       "7796806090_R04C01    0.764291    0.045026    0.967063    0.780857    0.039814   \n",
       "6285633051_R04C01    0.790845    0.022084    0.983528    0.836831    0.024214   \n",
       "9993943017_R04C02    0.771037    0.029470    0.975914    0.902240    0.032599   \n",
       "\n",
       "                      ...      ch.9.1173620F  cg04300684  cg16770054  \\\n",
       "7796806090_R04C01     ...           0.037846    0.606236    0.931593   \n",
       "6285633051_R04C01     ...           0.022224    0.636163    0.962394   \n",
       "9993943017_R04C02     ...           0.041737    0.697151    0.967159   \n",
       "\n",
       "                   cg18900959  cg14847845  cg23107916  cg16751754  cg15457745  \\\n",
       "7796806090_R04C01    0.926697    0.860495    0.698333    0.932990    0.022119   \n",
       "6285633051_R04C01    0.942780    0.848625    0.553571    0.961438    0.012269   \n",
       "9993943017_R04C02    0.921050    0.807059    0.539523    0.965884    0.018012   \n",
       "\n",
       "                   cg00849943  cg17289222  \n",
       "7796806090_R04C01    0.015452    0.980561  \n",
       "6285633051_R04C01    0.008690    0.993206  \n",
       "9993943017_R04C02    0.019237    0.994381  \n",
       "\n",
       "[3 rows x 300000 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How well does the model reconstruct the input Methylation data\n",
    "input_methyl_reconstruct = decoder.predict(np.array(encoded_methyl_df))\n",
    "input_methyl_reconstruct = pd.DataFrame(input_methyl_reconstruct, index=methyl_df2.index,\n",
    "                                        columns=methyl_df2.columns)\n",
    "input_methyl_reconstruct.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(862, 300000)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cg05609218</th>\n",
       "      <th>cg22931085</th>\n",
       "      <th>cg17251874</th>\n",
       "      <th>cg15207619</th>\n",
       "      <th>cg18069268</th>\n",
       "      <th>cg11787508</th>\n",
       "      <th>cg13337949</th>\n",
       "      <th>cg04485516</th>\n",
       "      <th>cg01828530</th>\n",
       "      <th>cg09648722</th>\n",
       "      <th>...</th>\n",
       "      <th>ch.9.1173620F</th>\n",
       "      <th>cg04300684</th>\n",
       "      <th>cg16770054</th>\n",
       "      <th>cg18900959</th>\n",
       "      <th>cg14847845</th>\n",
       "      <th>cg23107916</th>\n",
       "      <th>cg16751754</th>\n",
       "      <th>cg15457745</th>\n",
       "      <th>cg00849943</th>\n",
       "      <th>cg17289222</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7796806090_R04C01</th>\n",
       "      <td>0.545441</td>\n",
       "      <td>0.853057</td>\n",
       "      <td>0.649835</td>\n",
       "      <td>0.259499</td>\n",
       "      <td>0.938481</td>\n",
       "      <td>0.526505</td>\n",
       "      <td>0.128962</td>\n",
       "      <td>0.884376</td>\n",
       "      <td>0.770399</td>\n",
       "      <td>0.100277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087824</td>\n",
       "      <td>0.487777</td>\n",
       "      <td>0.875961</td>\n",
       "      <td>0.873091</td>\n",
       "      <td>0.874440</td>\n",
       "      <td>0.653986</td>\n",
       "      <td>0.917380</td>\n",
       "      <td>0.047611</td>\n",
       "      <td>0.044446</td>\n",
       "      <td>0.699034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6285633051_R04C01</th>\n",
       "      <td>0.664495</td>\n",
       "      <td>0.821738</td>\n",
       "      <td>0.551126</td>\n",
       "      <td>0.240213</td>\n",
       "      <td>0.934988</td>\n",
       "      <td>0.462401</td>\n",
       "      <td>0.070426</td>\n",
       "      <td>0.943853</td>\n",
       "      <td>0.624185</td>\n",
       "      <td>0.087996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103713</td>\n",
       "      <td>0.509940</td>\n",
       "      <td>0.838878</td>\n",
       "      <td>0.896937</td>\n",
       "      <td>0.679916</td>\n",
       "      <td>0.429626</td>\n",
       "      <td>0.762457</td>\n",
       "      <td>0.037634</td>\n",
       "      <td>0.033631</td>\n",
       "      <td>0.976383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993943017_R04C02</th>\n",
       "      <td>0.592440</td>\n",
       "      <td>0.777425</td>\n",
       "      <td>0.292605</td>\n",
       "      <td>0.178106</td>\n",
       "      <td>0.571350</td>\n",
       "      <td>0.886400</td>\n",
       "      <td>0.125322</td>\n",
       "      <td>0.867190</td>\n",
       "      <td>0.750185</td>\n",
       "      <td>0.094839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157848</td>\n",
       "      <td>0.600940</td>\n",
       "      <td>0.918040</td>\n",
       "      <td>0.833179</td>\n",
       "      <td>0.676394</td>\n",
       "      <td>0.380983</td>\n",
       "      <td>0.903616</td>\n",
       "      <td>0.041686</td>\n",
       "      <td>0.049972</td>\n",
       "      <td>0.901056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 300000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   cg05609218  cg22931085  cg17251874  cg15207619  cg18069268  \\\n",
       "7796806090_R04C01    0.545441    0.853057    0.649835    0.259499    0.938481   \n",
       "6285633051_R04C01    0.664495    0.821738    0.551126    0.240213    0.934988   \n",
       "9993943017_R04C02    0.592440    0.777425    0.292605    0.178106    0.571350   \n",
       "\n",
       "                   cg11787508  cg13337949  cg04485516  cg01828530  cg09648722  \\\n",
       "7796806090_R04C01    0.526505    0.128962    0.884376    0.770399    0.100277   \n",
       "6285633051_R04C01    0.462401    0.070426    0.943853    0.624185    0.087996   \n",
       "9993943017_R04C02    0.886400    0.125322    0.867190    0.750185    0.094839   \n",
       "\n",
       "                      ...      ch.9.1173620F  cg04300684  cg16770054  \\\n",
       "7796806090_R04C01     ...           0.087824    0.487777    0.875961   \n",
       "6285633051_R04C01     ...           0.103713    0.509940    0.838878   \n",
       "9993943017_R04C02     ...           0.157848    0.600940    0.918040   \n",
       "\n",
       "                   cg18900959  cg14847845  cg23107916  cg16751754  cg15457745  \\\n",
       "7796806090_R04C01    0.873091    0.874440    0.653986    0.917380    0.047611   \n",
       "6285633051_R04C01    0.896937    0.679916    0.429626    0.762457    0.037634   \n",
       "9993943017_R04C02    0.833179    0.676394    0.380983    0.903616    0.041686   \n",
       "\n",
       "                   cg00849943  cg17289222  \n",
       "7796806090_R04C01    0.044446    0.699034  \n",
       "6285633051_R04C01    0.033631    0.976383  \n",
       "9993943017_R04C02    0.049972    0.901056  \n",
       "\n",
       "[3 rows x 300000 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(methyl_df2.shape)\n",
    "methyl_df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#methylation_out_file = os.path.join('data', 'TCGA_BRCA_30kgenerated_cpg.tsv')\n",
    "methylation_out_file = os.path.join('data', 'TCGA_BRCA_300kgenerated_cpg_100latent.tsv')\n",
    "methyl_df2.to_csv(methylation_out_file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#encoder_model_file = os.path.join('models', 'encoder_onehidden_vae_100K-10.hdf5')\n",
    "#decoder_model_file = os.path.join('models', 'decoder_onehidden_vae_100K-10.hdf5')\n",
    "\n",
    "#encoder_model_file = os.path.join('models', 'encoder_onehidden_vae_100K-100.hdf5')\n",
    "#decoder_model_file = os.path.join('models', 'decoder_onehidden_vae_100K-100.hdf5')\n",
    "\n",
    "#encoder_model_file = os.path.join('models', 'encoder_onehidden_vae_10K-100.hdf5')\n",
    "#decoder_model_file = os.path.join('models', 'decoder_onehidden_vae_10K-100.hdf5')\n",
    "\n",
    "#encoder_model_file = os.path.join('models', 'encoder_onehidden_vae_30K-1000.hdf5')\n",
    "#decoder_model_file = os.path.join('models', 'decoder_onehidden_vae_30K-1000.hdf5')\n",
    "\n",
    "#encoder_model_file = os.path.join('models', 'encoder_onehidden_vae_300K-1000.hdf5')\n",
    "#decoder_model_file = os.path.join('models', 'decoder_onehidden_vae_300K-1000.hdf5')\n",
    "\n",
    "encoder_model_file = os.path.join('models', 'encoder_onehidden_vae_300K-100.hdf5')\n",
    "decoder_model_file = os.path.join('models', 'decoder_onehidden_vae_300K-100.hdf5')\n",
    "\n",
    "encoder.save(encoder_model_file)\n",
    "decoder.save(decoder_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
